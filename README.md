# Landmark-Classification

This project demonstrates how to train and evaluate Convolutional Neural Networks (CNNs) for image classification using **PyTorch**.  
It includes three main workflows: training a CNN from scratch, applying transfer learning, and deploying a simple prediction app.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ cnn_from_scratch.ipynb   # Training a custom CNN from scratch
â”œâ”€â”€ transfer_learning.ipynb  # Transfer learning with pretrained ResNet
â”œâ”€â”€ app.ipynb                # Simple inference and demo app
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ helpers.py           # Project utilities
â”‚   â”œâ”€â”€ model.py             # Custom CNN architecture
â”‚   â”œâ”€â”€ transfer.py          # Transfer learning model builder
â”‚   â”œâ”€â”€ train.py             # Training, validation, testing loops
â”‚   â”œâ”€â”€ optimization.py      # Loss functions and optimizers
â”‚   â”œâ”€â”€ predictor.py         # Inference helper
â”‚   â””â”€â”€ data.py              # Data loading and preprocessing
```

---

## ğŸš€ Workflows

### 1. CNN From Scratch
- Implements a custom CNN defined in `model.py`.
- Architecture: **5 convolutional blocks** (Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPool), followed by fully connected layers with dropout.
- Trained with **CrossEntropyLoss** and optimizers (SGD/Adam).
- Pros: full control of the architecture.  
- Cons: requires more training data and computation.

### 2. Transfer Learning
- Uses a **ResNet18 pretrained on ImageNet** (`torchvision.models`).
- Freezes all backbone layers (`requires_grad=False`).
- Replaces the final fully connected layer with a custom linear classifier for our dataset (50 classes by default).
- Much faster training and better performance on small datasets.

### 3. Inference App
- Loads a trained model checkpoint.
- Uses `predictor.py` to preprocess input images and predict class labels.
- Demonstrates how to move from training to deployment.

---

## âš™ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/CarlosYazid/Landmark-Classification.git
   cd cnn-image-classification
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

   Main dependencies:
   - PyTorch
   - Torchvision
   - Matplotlib
   - tqdm
   - livelossplot

---

## ğŸ›  Usage

### Training from scratch
```bash
jupyter notebook cnn_from_scratch.ipynb
```

### Transfer learning
```bash
jupyter notebook transfer_learning.ipynb
```

### Run inference app
```bash
jupyter notebook app.ipynb
```

---

## ğŸ“Š Results
- **From Scratch**: flexible architecture, but requires more epochs to converge.
- **Transfer Learning**: achieves higher accuracy with fewer epochs by leveraging pretrained features.
- **App**: demonstrates how to perform predictions on unseen images.

---

## ğŸ”¬ Key Files

- `src/model.py` â†’ Custom CNN (`MyModel`)  
- `src/transfer.py` â†’ Transfer learning setup with pretrained ResNet  
- `src/train.py` â†’ Training/validation loops, early stopping, learning rate scheduling  
- `src/optimization.py` â†’ Loss and optimizer selection  
- `src/predictor.py` â†’ Preprocessing and prediction logic  

---

## ğŸ“Œ Notes
- Images are resized to **224Ã—224** pixels for consistency.  
- Data augmentation (flips, crops, rotations) improves generalization when training from scratch.  
- Validation loss is tracked, and the model is checkpointed when improvement is detected.  
- Learning rate scheduling (`ReduceLROnPlateau`) is used to stabilize training.

---

## ğŸ“– License
This project is for **educational purposes**. You are free to use and adapt it under the MIT license.
